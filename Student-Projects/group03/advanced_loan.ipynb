{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ddb601",
   "metadata": {},
   "source": [
    "# Advanced Loan Creditworthiness Prediction\n",
    "\n",
    "This notebook upgrades the baseline into a leakage-safe, reproducible, portfolio-grade ML workflow:\n",
    "- Proper preprocessing with `ColumnTransformer` + `Pipeline`\n",
    "- One-Hot encoding for categorical variables\n",
    "- Robust imputation\n",
    "- Stratified splitting + cross-validation\n",
    "- Multiple evaluation metrics (ROC-AUC, F1, etc.)\n",
    "- Hyperparameter tuning\n",
    "- Threshold tuning\n",
    "- Model export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143fee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1be19",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9cff1",
   "metadata": {},
   "source": [
    "## Basic checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6062201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.isna().sum(), df['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a1455",
   "metadata": {},
   "source": [
    "## Feature engineering (simple but effective)\n",
    "We add:\n",
    "- `TotalIncome = ApplicantIncome + CoapplicantIncome`\n",
    "- `LoanAmount_to_Income = LoanAmount / TotalIncome`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d22fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df['TotalIncome'] = df['ApplicantIncome'].fillna(0) + df['CoapplicantIncome'].fillna(0)\n",
    "df['LoanAmount_to_Income'] = df['LoanAmount'] / df['TotalIncome'].replace(0, np.nan)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603983ac",
   "metadata": {},
   "source": [
    "## Split X/y and train/test\n",
    "Key upgrade: **stratified split** so the class ratio is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8baf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Loan_Status'\n",
    "ID_COL = 'Loan_ID'\n",
    "\n",
    "X = df.drop(columns=[TARGET, ID_COL])\n",
    "y = df[TARGET].map({'Y': 1, 'N': 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b91c149",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline\n",
    "Leakage-safe preprocessing with `ColumnTransformer`:\n",
    "- Numeric: median imputation + scaling\n",
    "- Categorical: most-frequent imputation + one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3184020",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [c for c in X_train.columns if X_train[c].dtype == 'object']\n",
    "numeric_cols = [c for c in X_train.columns if c not in categorical_cols]\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', numeric_pipe, numeric_cols),\n",
    "    ('cat', categorical_pipe, categorical_cols),\n",
    "], verbose_feature_names_out=False)\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b5cfc",
   "metadata": {},
   "source": [
    "## Model benchmarking (cross-validation)\n",
    "We compare several scikit-learn models using 5-fold Stratified CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'logreg_balanced': LogisticRegression(max_iter=20000, class_weight='balanced'),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=600, class_weight='balanced_subsample', random_state=42, n_jobs=-1),\n",
    "    'grad_boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'hist_gbdt': HistGradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {'accuracy':'accuracy','precision':'precision','recall':'recall','f1':'f1','roc_auc':'roc_auc'}\n",
    "\n",
    "rows = []\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([('preprocess', preprocess), ('model', model)])\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    row = {'model': name}\n",
    "    for k, v in scores.items():\n",
    "        if k.startswith('test_'):\n",
    "            row[k.replace('test_','')] = float(np.mean(v))\n",
    "    rows.append(row)\n",
    "\n",
    "bench = pd.DataFrame(rows).sort_values('roc_auc', ascending=False).reset_index(drop=True)\n",
    "bench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908a1ab",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (Logistic Regression)\n",
    "Logistic Regression is a strong and explainable baseline. We tune `C` for ROC-AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', LogisticRegression(max_iter=20000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_dist = {'model__C': np.logspace(-3, 3, 80)}\n",
    "search = RandomizedSearchCV(pipe, param_distributions=param_dist, n_iter=25, scoring='roc_auc', cv=cv, random_state=42, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "search.best_params_, search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834b1bd",
   "metadata": {},
   "source": [
    "## Evaluate best model on holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "proba = best_model.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "print('ROC-AUC:', roc_auc_score(y_test, proba))\n",
    "print('Accuracy:', accuracy_score(y_test, pred))\n",
    "print('Precision:', precision_score(y_test, pred, zero_division=0))\n",
    "print('Recall:', recall_score(y_test, pred, zero_division=0))\n",
    "print('F1:', f1_score(y_test, pred, zero_division=0))\n",
    "\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix(y_test, pred))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07efa863",
   "metadata": {},
   "source": [
    "## Threshold tuning\n",
    "Using a fixed 0.5 threshold is usually lazy. Tune a threshold for your objective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_threshold(y_true, proba, metric='f1'):\n",
    "    thresholds = np.linspace(0.05, 0.95, 91)\n",
    "    best_t, best_s = 0.5, -1\n",
    "    for t in thresholds:\n",
    "        p = (proba >= t).astype(int)\n",
    "        if metric == 'f1':\n",
    "            s = f1_score(y_true, p, zero_division=0)\n",
    "        elif metric == 'recall':\n",
    "            s = recall_score(y_true, p, zero_division=0)\n",
    "        elif metric == 'precision':\n",
    "            s = precision_score(y_true, p, zero_division=0)\n",
    "        else:\n",
    "            raise ValueError('metric must be f1/recall/precision')\n",
    "        if s > best_s:\n",
    "            best_t, best_s = float(t), float(s)\n",
    "    return best_t, best_s\n",
    "\n",
    "t, s = best_threshold(y_test.to_numpy(), proba, metric='f1')\n",
    "t, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tuned = (proba >= t).astype(int)\n",
    "print('Threshold:', t)\n",
    "print('Accuracy:', accuracy_score(y_test, pred_tuned))\n",
    "print('Precision:', precision_score(y_test, pred_tuned, zero_division=0))\n",
    "print('Recall:', recall_score(y_test, pred_tuned, zero_division=0))\n",
    "print('F1:', f1_score(y_test, pred_tuned, zero_division=0))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, proba))\n",
    "print('\\nConfusion matrix (tuned):\\n', confusion_matrix(y_test, pred_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12afd946",
   "metadata": {},
   "source": [
    "## Optional: Probability calibration\n",
    "If you will use predicted probabilities in business decisioning, calibration can matter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea299587",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = CalibratedClassifierCV(best_model, method='sigmoid', cv=3)\n",
    "cal.fit(X_train, y_train)\n",
    "proba_cal = cal.predict_proba(X_test)[:, 1]\n",
    "print('ROC-AUC (calibrated):', roc_auc_score(y_test, proba_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6da38",
   "metadata": {},
   "source": [
    "## Permutation importance (Top 15)\n",
    "A portable explainability method that works with many models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1388252",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "pre = best_model.named_steps['preprocess']\n",
    "mdl = best_model.named_steps['model']\n",
    "X_test_tr = pre.transform(X_test)\n",
    "feature_names = pre.get_feature_names_out()\n",
    "\n",
    "r = permutation_importance(mdl, X_test_tr, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "imp = pd.DataFrame({'feature': feature_names, 'importance_mean': r.importances_mean})\n",
    "imp = imp.sort_values('importance_mean', ascending=False).head(15)\n",
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a3e7c",
   "metadata": {},
   "source": [
    "## Export model\n",
    "Export the trained pipeline for later inference (API, batch scoring, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, 'loan_model.joblib')\n",
    "print('Saved: loan_model.joblib')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
