import librosa
import numpy as np
import tensorflow_hub as hub
import joblib
import os


# Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
SAMPLE_RATE = 16000              # Ù†Ø±Ø® Ù†Ù…ÙˆÙ†Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒ YAMNet
MODEL_DIR = "model"              # Ù¾ÙˆØ´Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ù…Ø¯Ù„ Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø¯Ø§Ø®Ù„Ø´ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒØ´Ù†

MODEL_PATH = os.path.join(MODEL_DIR, "svm_model.pkl")
SCALER_PATH = os.path.join(MODEL_DIR, "scaler.pkl")
ENCODER_PATH = os.path.join(MODEL_DIR, "label_encoder.pkl")


# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ YAMNet
# Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø§Ø² Ù‚Ø¨Ù„ train Ø´Ø¯Ù‡ Ùˆ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒØ´Ù‡
YAMNET = hub.load("https://tfhub.dev/google/yamnet/1")


# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ lazy-load Ø´Ø¯Ù‡
# Ø§ÛŒÙ†Ø§ Ø§ÙˆÙ„Ø´ None Ù‡Ø³ØªÙ† Ùˆ ÙÙ‚Ø· ÙˆÙ‚ØªÛŒ Ù„Ø§Ø²Ù… Ø¨Ø´Ù‡ load Ù…ÛŒØ´Ù†
svm_model = None
scaler = None
label_encoder = None


def load_model_if_needed():
    """
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ÙÙ‚Ø· ÙˆÙ‚ØªÛŒ Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù„Ø§Ø²Ù… Ø¨Ø§Ø´Ù‡
    ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ train Ø´Ø¯Ù‡ Ø±Ùˆ Ø§Ø² Ø¯ÛŒØ³Ú© load Ù…ÛŒâ€ŒÚ©Ù†Ù‡
    (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² load Ø´Ø¯Ù† Ø¨ÛŒâ€ŒÙ…ÙˆØ±Ø¯ Ù…ÙˆÙ‚Ø¹ Ø§Ø¬Ø±Ø§ÛŒ UI)
    """
    global svm_model, scaler, label_encoder

    # Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ load Ø´Ø¯Ù‡ØŒ Ø¯ÛŒÚ¯Ù‡ Ú©Ø§Ø±ÛŒ Ù†Ú©Ù†
    if svm_model is not None:
        return

    # Ø§Ú¯Ø± Ù…Ø¯Ù„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡ ÛŒØ¹Ù†ÛŒ Ù‡Ù†ÙˆØ² train Ù†Ø´Ø¯Ù‡
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError("Model is not trained yet")

    # load Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡
    svm_model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    label_encoder = joblib.load(ENCODER_PATH)


# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ YAMNet
def extract_yamnet_features(audio_path, progress_callback=None):
    """
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ùˆ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù‡ØŒ
    Ù…ÛŒâ€ŒÙØ±Ø³ØªÙ‡ Ø¨Ù‡ YAMNet
    Ùˆ embedding Ù†Ù‡Ø§ÛŒÛŒ Ø±Ùˆ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯ÙˆÙ†Ù‡
    """
    # Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ mono
    audio, _ = librosa.load(audio_path, sr=SAMPLE_RATE, mono=True)
    waveform = audio.astype(np.float32)

    # Ú¯Ø±ÙØªÙ† embedding Ø§Ø² YAMNet
    scores, embeddings, _ = YAMNET(waveform)

    # Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª progress (Ø§ÛŒÙ†Ø¬Ø§ ÙÙ‚Ø· ÛŒÙ‡ Ù…Ø±Ø­Ù„Ù‡ Ø¯Ø§Ø±ÛŒÙ…)
    if progress_callback:
        progress_callback(1, 1)

    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú¯Ø±ÙØªÙ† Ø§Ø² embeddingâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¨Ø±Ø¯Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
    return np.mean(embeddings.numpy(), axis=0)


# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú˜Ø§Ù†Ø± Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ confidence
def predict_genre_with_confidence(audio_path, progress_callback=None):
    """
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ú˜Ø§Ù†Ø± Ø¢Ù‡Ù†Ú¯ Ø±Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
    Ùˆ Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù‡Ø± Ú˜Ø§Ù†Ø± Ø±Ùˆ Ù‡Ù… Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯ÙˆÙ†Ù‡
    """

    # ğŸ”´ Ø§ÙˆÙ„ Ù…Ø·Ù…Ø¦Ù† Ù…ÛŒØ´ÛŒÙ… Ù…Ø¯Ù„ load Ø´Ø¯Ù‡
    load_model_if_needed()

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
    features = extract_yamnet_features(
        audio_path,
        progress_callback
    )

    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ø³Ú©ÛŒÙ„Ø±ÛŒ Ú©Ù‡ Ù…ÙˆÙ‚Ø¹ train Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
    features = scaler.transform([features])

    # Ú¯Ø±ÙØªÙ† Ø§Ø­ØªÙ…Ø§Ù„ Ù‡Ø± Ú©Ù„Ø§Ø³ Ø§Ø² SVM
    probabilities = svm_model.predict_proba(features)[0]

    # Ø§ÛŒÙ†Ø¯Ú©Ø³ Ú˜Ø§Ù†Ø±ÛŒ Ú©Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§Ø­ØªÙ…Ø§Ù„ Ø±Ùˆ Ø¯Ø§Ø±Ù‡
    predicted_index = np.argmax(probabilities)

    # ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ¨Ù„ Ø¹Ø¯Ø¯ÛŒ Ø¨Ù‡ Ø§Ø³Ù… Ú˜Ø§Ù†Ø±
    predicted_genre = label_encoder.inverse_transform(
        [predicted_index]
    )[0]

    # Ø³Ø§Ø®Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ confidence Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± UI
    confidence_dict = {
        label_encoder.inverse_transform([i])[0]: prob
        for i, prob in enumerate(probabilities)
    }

    return predicted_genre, confidence_dict
