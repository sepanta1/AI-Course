import os
import librosa
import numpy as np
import tensorflow_hub as hub
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import joblib


# Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ YAMNet
# (Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù‡Ù…ÙˆÙ†ÛŒ Ú©Ù‡ Ù…ÙˆÙ‚Ø¹ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)
yamnet_model = hub.load("https://tfhub.dev/google/yamnet/1")

TARGET_SAMPLE_RATE = 16000


# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ø² ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
def extract_audio_features(audio_file_path):
    """
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹:
    - ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ùˆ Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
    - Ù…ÛŒâ€ŒÙØ±Ø³ØªØªØ´ Ø¯Ø§Ø®Ù„ YAMNet
    - Ø¯Ø± Ù†Ù‡Ø§ÛŒØª ÛŒÚ© embedding Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯ÙˆÙ†Ù‡
    """

    audio_signal, _ = librosa.load(
        audio_file_path,
        sr=TARGET_SAMPLE_RATE,
        mono=True
    )

    waveform = audio_signal.astype(np.float32)

    # Ø®Ø±ÙˆØ¬ÛŒ YAMNet Ø´Ø§Ù…Ù„ scoreØŒ embedding Ùˆ spectrogram Ù‡Ø³Øª
    _, embeddings, _ = yamnet_model(waveform)

    # Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø·ÙˆÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø«Ø§Ø¨Øª Ø¨Ø§Ø´Ù‡ØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
    return np.mean(embeddings.numpy(), axis=0)


# Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§Ø³Øª Ø§Ø² ÙÙˆÙ„Ø¯Ø± Ú˜Ø§Ù†Ø±Ù‡Ø§
def build_training_dataset(dataset_root_path):
    """
    Ø³Ø§Ø®Øª X Ùˆ y Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± ÙÙˆÙ„Ø¯Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª
    Ù‡Ø± ÙÙˆÙ„Ø¯Ø± = ÛŒÚ© Ú˜Ø§Ù†Ø±
    """

    feature_vectors = []
    genre_labels = []

    for genre_name in os.listdir(dataset_root_path):
        genre_folder_path = os.path.join(dataset_root_path, genre_name)

        # Ø§Ú¯Ù‡ ÙØ§ÛŒÙ„ Ø¨ÙˆØ¯ ÛŒØ§ ÙÙˆÙ„Ø¯Ø± Ù†Ø¨ÙˆØ¯ØŒ Ø¨ÛŒâ€ŒØ®ÛŒØ§Ù„Ø´ Ù…ÛŒâ€ŒØ´ÛŒÙ…
        if not os.path.isdir(genre_folder_path):
            continue

        for file_name in os.listdir(genre_folder_path):
            if not file_name.endswith(".wav"):
                continue

            audio_file_path = os.path.join(genre_folder_path, file_name)

            try:
                features = extract_audio_features(audio_file_path)
                feature_vectors.append(features)
                genre_labels.append(genre_name)

            except Exception as error:
                # Ø§Ú¯Ù‡ ÛŒÙ‡ ÙØ§ÛŒÙ„ Ø®Ø±Ø§Ø¨ Ø¨ÙˆØ¯ØŒ Ú©Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù†Ø®ÙˆØ§Ø¨Ù‡
                print(f"âŒ Error while processing file {audio_file_path}: {error}")

    return np.array(feature_vectors), np.array(genre_labels)


# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
def main():
    print("ğŸ“ Building dataset...")

    X_features, y_genres = build_training_dataset(
        "data/genres_original"
    )

    print("ğŸ·ï¸ Encoding genre labels...")
    genre_label_encoder = LabelEncoder()
    y_encoded = genre_label_encoder.fit_transform(y_genres)

    print("ğŸ“ Scaling features...")
    feature_scaler = StandardScaler()
    X_scaled = feature_scaler.fit_transform(X_features)

    print("âœ‚ï¸ Splitting data into train and test sets...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled,
        y_encoded,
        test_size=0.2,
        random_state=42,
        stratify=y_encoded
    )

    print("ğŸ¤– Training SVM model...")
    svm_genre_model = SVC(
        kernel="rbf",
        C=10,
        gamma="scale",
        probability=True,        # Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¨ØªÙˆÙ†ÛŒÙ… confidence Ø­Ø³Ø§Ø¨ Ú©Ù†ÛŒÙ…
        class_weight="balanced"  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ ÛŒÙ‡ Ú˜Ø§Ù†Ø± ØºØ§Ù„Ø¨ Ø¨Ø´Ù‡
    )

    svm_genre_model.fit(X_train, y_train)

    print(f"âœ… Training accuracy: {svm_genre_model.score(X_train, y_train):.3f}")
    print(f"âœ… Test accuracy:     {svm_genre_model.score(X_test, y_test):.3f}")

    # Ø°Ø®ÛŒØ±Ù‡ Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    os.makedirs("model", exist_ok=True)
    joblib.dump(svm_genre_model, "model/svm_model.pkl")
    joblib.dump(feature_scaler, "model/scaler.pkl")
    joblib.dump(genre_label_encoder, "model/label_encoder.pkl")

    print("ğŸ’¾ Model, scaler, and label encoder saved successfully.")


if __name__ == "__main__":
    main()
